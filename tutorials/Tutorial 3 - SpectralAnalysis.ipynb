{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4VX-Tus2EbUK",
    "outputId": "8ac66adc-705b-4719-ec66-645d110c6575"
   },
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/pnnl/DeepDataProfiler.git\n",
    "!pip install pytorchcv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b7Utfpq4EaUF"
   },
   "source": [
    "## Deep Data Profiler and Spectral Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "goY06-o9EaUI"
   },
   "source": [
    "The DeepDataProfiler methods featured in this tutorial are largely based on two papers (listed below) that borrow methods from Random Matrix Theory and statistical physics.\n",
    "\n",
    "These methods act only on the weights of the Fully Connected and\n",
    "Convolutional layers a deep neural network. Despite this, they have\n",
    "proven effective in predicting\n",
    "1. Test accuracies with no access to the data distribution on which it was trained OR tested \n",
    "2. Relative performance between models of similar architecture classes\n",
    "3. Model and architecture improvements while training\n",
    "\n",
    "See more at the bottom of this tutorial for references, as well as some details on our improvements over the original work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_M1D_f3rEaUJ"
   },
   "source": [
    "**The core observation these metrics use, following results from Random Matrix Theory, is that the covariance of the weight matrices $X = W^TW$, of DNN layers start out looking like the left plot below. As these layers are trained by Stochastic Gradient Descent, the ESD (empirical spectral distribution) of $X$ systematically gain fat-tails, like the plot on the right (which is a layer that has been trained on ImageNet).** \n",
    "\n",
    "We can use this measure to know how much a layer (or entire model) has been trained, and how likely it is that a layer (or model) has been overfit. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MzdvSAtYEaUJ"
   },
   "source": [
    "<table>\n",
    "    <caption style=\"caption-side:bottom\" display=\"table-caption\" > Eigenvalue spectral distribution of weights of a a network with random initialization (left) and a trained network (right)</caption>\n",
    "    <tr>\n",
    "<td> <img src=\"https://github.com/pnnl/DeepDataProfiler/blob/master/tutorials/images/random_init_ESD.png?raw=1\" alt=\"ESD of weights of a random initialization\" style=\"width: 350px;\"/> </td>\n",
    "<td> <img src=\"https://github.com/pnnl/DeepDataProfiler/blob/master/tutorials/images/trained_ESD.png?raw=1\" alt=\"ESD of weights of a trained network\" style=\"width: 350px;\"/> </td>\n",
    "</tr></table>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y__n7CbbEaUK"
   },
   "outputs": [],
   "source": [
    "# first, we import the DeepDataProfiler and PyTorch\n",
    "import deep_data_profiler as ddp\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import pytorchcv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SYWtaMTxEaUK"
   },
   "source": [
    "### First scenario\n",
    "\n",
    "We are given two models. (Pretend) we have no knowledge of the data the models have been trained on, where they came from, etc. We just download the weights from the PyTorch website, and can compare their per layer and total performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8qvSVz2aEaUL"
   },
   "outputs": [],
   "source": [
    "import torchvision.models as tvmodels\n",
    "\n",
    "model_random_init = tvmodels.resnet18(pretrained=False).eval()\n",
    "\n",
    "model_trained = tvmodels.resnet18(pretrained=True).eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ztsrIZSSEaUL"
   },
   "source": [
    "#### We can also examine the individual layers of the models to profile the extent of their training. \n",
    "\n",
    "As noted, we expect the spectral distribution of the trained models to show evidence of fat-tails. For the below example, we choose to plot the Empirical Spectral Distributions for the layers. \n",
    "\n",
    "We make per layer predictions (with the `.layer_RMT()` method) based on the fit of the power law coefficient $\\alpha$, where very Heavy=Tailed distributions are mostly expected to be better trained. Per Martin and Mahoney, different fits fall under different Universality classes of Heavy-Tailed matrices. Namely, for $\\mu =  2(\\alpha - 1)$, we threshold on $0< \\mu <4$ for good regularization and performance, $4\\leq \\mu <7$ for likely good performance but not as well regularized, and $\\mu \\geq7$ for poor regularization and poor test performance.\n",
    "\n",
    "**First, for the randomly initialized model:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "57C6-wXlEaUL",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# initialize ddp.SpectralAnalysis for the randomly initialized model\n",
    "analysis_random_init = ddp.SpectralAnalysis(model_random_init)\n",
    "\n",
    "# compute the SVD of X for each layer, return in dict\n",
    "eigenvalue_dictionary_random = analysis_random_init.spectral_analysis()\n",
    "\n",
    "# fit a power law distribution for each spectral distribution computed, per layer \n",
    "alpha_dictionary_random = analysis_random_init.fit_power_law(eig_dict=eigenvalue_dictionary_random)\n",
    "\n",
    "# threshold on the \"fat-tailedness\" of the power-law distribution\n",
    "layer_phenomenology_random = analysis_random_init.layer_RMT(alpha_dict=alpha_dictionary_random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w1dQuJt6EaUM"
   },
   "source": [
    "You can can plot the empirical spectral distribution for all of the layers by calling `analysis_random_init.layer_RMT(plot_eig=True)`. We make plots for a few representative layers. We first **compute the same metrics for the ImageNet trained model:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u1StRnAlEaUM",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# initialize ddp.SpectralAnalysis for the model trained on ImageNet\n",
    "analysis_trained = ddp.SpectralAnalysis(model_trained)\n",
    "\n",
    "# compute the SVD of X for each layer, return in dict\n",
    "eigenvalue_dict_trained = analysis_trained.spectral_analysis()\n",
    "\n",
    "# fit a power law distribution for each spectral distribution computed, per layer \n",
    "alpha_dict_trained = analysis_trained.fit_power_law(eig_dict=eigenvalue_dict_trained)\n",
    "\n",
    "# threshold on the \"fat-tailedness\" of the power-law distribution\n",
    "layer_phenomenology_trained = analysis_trained.layer_RMT(alpha_dict=alpha_dict_trained)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7o_8xHKCEaUN"
   },
   "source": [
    "We plot a sample of the layers side-by-side below. Notice that (1) these plots qualitatively match the comparison of the plots above of the ESD of weights of a trained network and a network with random initialization and (2) the power law fit shows that the well-trained layers have fat-tails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "qg_4vxRXEaUN",
    "outputId": "67d68ed1-587b-4536-a221-a8dcd3dfa51c",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# iterate through the final layers, which the dicts use as keys\n",
    "layers = list(alpha_dict_trained.items())[14:]\n",
    "for idx, (layer, _) in enumerate(layers):\n",
    "    \n",
    "    # grab eigenvalues from the trained and random dicts\n",
    "    eigenvalues_random, _ = eigenvalue_dictionary_random[layer]\n",
    "    eigenvalues_trained, _ = eigenvalue_dict_trained[layer]\n",
    "    \n",
    "    # power law alphas\n",
    "    alpha_random, _ = alpha_dictionary_random[layer]\n",
    "    alpha_trained, _ = alpha_dict_trained[layer]\n",
    "    \n",
    "    # and get the per-layer regularization predictions\n",
    "    phenom_random = layer_phenomenology_random[14+idx]\n",
    "    phenom_trained = layer_phenomenology_trained[14+idx]\n",
    "    \n",
    "    \n",
    "    fig, axs = plt.subplots(1, 2, constrained_layout=True)\n",
    "    axs[0].hist(eigenvalues_random, bins=\"auto\", density=True)\n",
    "    axs[0].set_title(\"Randomly initialized network \\n power-law fit\" + fr\" $\\alpha$ = {round(alpha_random, 1)}\")\n",
    "    axs[0].set_xlabel('Eigenvalues of $X$', fontsize = 14)\n",
    "    axs[0].set_ylabel('ESD', fontsize = 14)\n",
    "\n",
    "\n",
    "    axs[1].hist(eigenvalues_trained, bins=\"auto\", density=True)\n",
    "    axs[1].set_title(\"ImageNet trained network \\n power-law fit\" + fr\" $\\alpha$ = {round(alpha_trained, 1)}\")\n",
    "    axs[1].set_xlabel('Eigenvalues of $X$', fontsize = 14)\n",
    "    axs[1].set_ylabel('ESD', fontsize = 14)\n",
    "\n",
    "\n",
    "    fig.suptitle(f\"Layer {layer} spectral distributions\", fontsize=16)\n",
    "    \n",
    "    plt.show()\n",
    "    print(f\"Randomly initialized network {phenom_random}\")\n",
    "    print(f\"ImageNet trained network {phenom_trained}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GSIybhnpEaUO"
   },
   "source": [
    "### \"Universal\" capacity metric\n",
    "**We can also output a single metric that allows us to make a good prediction about the relative performance of the models.** \n",
    "\n",
    "Here, we use the Universal capacity metric, defined as $\\hat{\\alpha}=\\frac{1}{L} \\sum_{l} \\alpha_{l} \\log \\lambda_{\\max , l}$, where $L$ is the number of layers of the network and $l$ the specific layers, $\\alpha_L$ is the power-law fit for the layer, and $\\lambda_{\\max , l}$ the largest eigenvalue for the covariance of the weights $X$. For more on this metric, see https://arxiv.org/abs/2002.06716."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VMq6X5B6EaUP",
    "outputId": "7648aeae-ef7e-43b5-b6fe-eec055f1157c"
   },
   "outputs": [],
   "source": [
    "# with a single metric, we can know the better trained model\n",
    "metric_trained = analysis_trained.universal_metric()\n",
    "metric_random = analysis_random_init.universal_metric()\n",
    "\n",
    "print(f\"The trained model's metric: {round(metric_trained, 2)} (significantly larger, indicative of training)\")\n",
    "print(f\"The randomly initialized model's metric: {round(metric_random, 2)} (smaller, i.e. less-regularized)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tc4vLICXEaUP"
   },
   "source": [
    "### Second scenario, eigenvalue spectral distribution during training\n",
    "\n",
    "\n",
    "In this scenario, we track a small model as it trains with the metric. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4CsiDqzOEaUQ"
   },
   "outputs": [],
   "source": [
    "# define a small model to be trained on CIFAR-10\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "net = Net().to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EV5qMJqzEaUQ"
   },
   "source": [
    "Uncomment and run the lines below if you want to actually train the small model above on CIFAR-10 and track the SpectralAnalysis metric as it trains. The training loop takes roughly 3 minutes to run on a Tesla P100 GPU in Colab and 30 minutes to run on our CPU.\n",
    "\n",
    "If running in Colab, you should either run the training loop below or manually download the weights. Otherwise, you can also use our already trained weights provided in our repo in the cell below (after the training loop)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Ttv75O3bEaUQ",
    "outputId": "3c212aeb-0791-447a-dda8-01ebd3529095"
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from pathlib import Path\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# make path if it does not already exist\n",
    "Path(\"spectral_data/cifar_files/\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=16,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "per_epoch_loss = []\n",
    "test_loss = []\n",
    "test_error = []\n",
    "training_error = []\n",
    "\n",
    "for epoch in range(10):\n",
    "    running_loss = 0.0\n",
    "    net.train()\n",
    "    train_acc_total = 0.0\n",
    "    for i, data in enumerate(trainloader):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs.to(device))\n",
    "        train_outputs = torch.argmax(outputs, dim=1).to(device)\n",
    "        train_acc_total += (train_outputs == labels.to(device)).sum() \n",
    "\n",
    "        loss = criterion(outputs.to(device), labels.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # print every epoch\n",
    "    training_error.append(1 - (train_acc_total / len(trainset)).item())\n",
    "    per_epoch_loss.append(running_loss)\n",
    "    print('[%d, %5d] loss: %.3f' %\n",
    "        (epoch + 1, i + 1, running_loss))\n",
    "\n",
    "\n",
    "    running_test_loss = 0.0\n",
    "    net.eval()\n",
    "    test_acc_total = 0\n",
    "\n",
    "    for i, data in enumerate(testloader):\n",
    "        inputs, labels = data\n",
    "\n",
    "       # forward + backward + optimize\n",
    "        outputs = net(inputs.to(device))\n",
    "        test_outputs = torch.argmax(outputs, dim=1).to(device)\n",
    "        test_acc_total += (test_outputs == labels.to(device)).sum() \n",
    "\n",
    "        loss = criterion(outputs.to(device), labels.to(device))\n",
    "\n",
    "       # print statistics\n",
    "        running_test_loss += loss.item()\n",
    "\n",
    "    # print every epoch\n",
    "    test_error.append(1. - (test_acc_total / len(testset)).item())\n",
    "    test_loss.append(running_test_loss)\n",
    "    print('[%d, %5d] loss: %.3f' %\n",
    "        (epoch + 1, i + 1, running_test_loss))\n",
    "    running_test_loss = 0.0\n",
    "\n",
    "    PATH = f'spectral_data/cifar_files/cifar_net_{epoch}.pth'\n",
    "    torch.save(net.state_dict(), PATH)\n",
    "  \n",
    "    plt.plot(per_epoch_loss, '.', label=\"training loss\")\n",
    "    plt.plot(test_loss, '.', label=\"test loss\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HQBELRy8EaUR"
   },
   "source": [
    "#### Here, we use our already trained weights to check how well our model tracks performance.\n",
    "\n",
    "We plot the ESD for an arbitrarily chosen layer at each training step, and give it's power-law fit. **Note** that the power law $\\alpha_L$ fit for the distribution tends to decrease during the training as the ESDs gain fatter tails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J3STjrtXEaUR"
   },
   "outputs": [],
   "source": [
    "# define (if not pulled above) the precent train error and test error from the training epochs\n",
    "training_error = [0.56, 0.5, 0.46, 0.43, 0.41, 0.39, 0.37, 0.36, 0.34, 0.32]\n",
    "test_error = [0.53, 0.48, 0.46, 0.43, 0.42, 0.4, 0.39, 0.39, 0.38, 0.38]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 929
    },
    "id": "ErWH4-FSEaUR",
    "outputId": "67cbeb33-a47d-4a35-d1f5-349edd5bd5ff",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "universal_metrics = []    \n",
    "layer_to_observe = 3\n",
    "\n",
    "fig, axs = plt.subplots(4, 3, constrained_layout=True, figsize=(15, 15))\n",
    "\n",
    "for i in range(10):\n",
    "    PATH = f'spectral_data/cifar_files/cifar_net_{i}.pth'\n",
    "    net.load_state_dict(torch.load(PATH, map_location=torch.device('cpu') ))\n",
    "    \n",
    "    # define SpectralAnalysis, and calculate the model metric\n",
    "    analysis = ddp.SpectralAnalysis(net)\n",
    "    # compute the SVD of X for each layer, return in dict\n",
    "    eigenvalue_dict = analysis.spectral_analysis()\n",
    "    # fit a power law distribution for each spectral distribution computed, per layer \n",
    "    alpha_dict = analysis.fit_power_law(eig_dict=eigenvalue_dict)\n",
    "    \n",
    "    # choose an arbitrary layer to plot \n",
    "    eigenvalues, _ = eigenvalue_dict[layer_to_observe]\n",
    "    alpha, _ = alpha_dict[layer_to_observe]\n",
    "    axs[i//3, i%3].hist(eigenvalues, bins=\"auto\", density=True)\n",
    "    axs[i//3, i%3].set_title(\n",
    "        (fr\"Epoch {i}, power-law fit $\\alpha = {round(alpha, 2)}$\" \n",
    "         + f\"\\n train error: {int(training_error[i]*100)}% | test error: {int(test_error[i]*100)}%\"\n",
    "                             ), fontsize=18)\n",
    "    axs[i//3, i%3].set_xlabel('Eigenvalues of $X$', fontsize = 14)\n",
    "    axs[i//3, i%3].set_ylabel('ESD', fontsize = 14)\n",
    "\n",
    "    # collect the universal alpha metrics, per epoch\n",
    "    universal_metrics.append(analysis.universal_metric(alpha_dict=alpha_dict))\n",
    "\n",
    "fig.suptitle(f\"Training epoch spectral distributions, for layer {layer_to_observe}\", fontsize=24)\n",
    "axs[-1, -1].axis('off')  \n",
    "axs[-1, -2].axis('off')  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QSx0hgsOEaUS"
   },
   "source": [
    "**We plot the per epoch training results below** (note the different y-axes on the plots below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 328
    },
    "id": "_aDLRazkEaUS",
    "outputId": "dd52e358-dbfc-4a78-b7d1-5047b241781c"
   },
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "ax1.set_xlabel('Epoch(s)')\n",
    "ax1.set_ylabel('Percent error', color='tab:red')\n",
    "ax1.plot(training_error, '-o', color='tab:red', label=\"training error\")\n",
    "ax1.plot(test_error,'-o', color='tab:orange', label=\"test error\")\n",
    "\n",
    "ax1.tick_params(axis='y', labelcolor='tab:red')\n",
    "plt.legend(bbox_to_anchor=(1.15, 1), loc='upper left')\n",
    "\n",
    "\n",
    "ax2 = ax1.twinx()  \n",
    "\n",
    "color = 'darkblue'\n",
    "ax2.set_ylabel('alpha', color=color)  # we already handled the x-label with ax1\n",
    "ax2.plot(universal_metrics, '-o', color=color, label=\"alpha metric\")\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.15, 0.85), loc='upper left')\n",
    "\n",
    "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "plt.title(\"CIFAR-10, simple model \\n metric and loss vs training epoch\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NbQMRcr8EaUT"
   },
   "source": [
    "### Third scenario\n",
    "\n",
    "In this final scenario, we use the set of metrics to perform a mock architecture search for a family of models and a dataset. We have evidence that the Universal capacity metric, presented during training above, serves as a useful metric for the generalizability of a model and its performance on a test dataset. For example, we see that the metric tracks test error on ImageNet very well for the VGG architecture family of models. \n",
    "\n",
    "*We note that this metric may be particularly instructive when performing small architecture tweaks, e.g. when deciding whether or not to add batch normalization to an existing architecture*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9U__4aHkEaUT"
   },
   "source": [
    "<img src=\"https://github.com/pnnl/DeepDataProfiler/blob/master/tutorials/images/vgg_metrics.png?raw=1\" width=\"300\" height=\"300\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MqC6iPDjEaUT"
   },
   "source": [
    "In our scenario, instead of ImageNet, we consider the dataset [Caltech-UCSD Birds 200](http://www.vision.caltech.edu/visipedia/CUB-200.html) (\"CUB\"). We have some initial models trained on the CUB dataset (example images below). \n",
    "\n",
    "However, we do not have access to the test set. **Despite this, we need to choose a model that generalizes well to deploy on the dataset.** \n",
    "![CUB example images](images/collage_cub.jpeg \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3NI5BSiEEaUT"
   },
   "source": [
    "In this scenario, we will be considering ResNets with different numbers of hidden layers trained on [Caltech-UCSD Birds 200](http://www.vision.caltech.edu/visipedia/CUB-200.html). \n",
    "\n",
    "While this scenario considers the number of hidden layers, this same approach works for other architecture decisions: e.g. whether to add dropout, a batch normalization layer, or even whether to try a different loss function.\n",
    "\n",
    "We use a repository with models that have already been trained on the data. **Run the rest of the commented out cell below to download this repo with pip and grab the metric for these models. If you do not want to pull these models, we define the calculated metric below.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2SlY_X_LEaUT",
    "outputId": "be4baae7-9cfa-4acc-d7bb-7943a0c35db9",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install pytorchcv\n",
    "\n",
    "from pytorchcv.model_provider import get_model as ptcv_get_model\n",
    "\n",
    "cub_names = ['seresnet14_cub', \n",
    "             'seresnet16_cub', \n",
    "             'seresnet18_cub', \n",
    "             'seresnet26_cub']\n",
    "\n",
    "metrics = []\n",
    "for model_name in cub_names:\n",
    "    # define model\n",
    "    model = ptcv_get_model(model_name, pretrained=True).eval()\n",
    "    # define the profiler\n",
    "    analysis = ddp.SpectralAnalysis(model)\n",
    "    metric = analysis.universal_metric()\n",
    "    metrics.append(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pRtJPQxnP55U",
    "outputId": "9212abd1-677d-40e7-e511-e9738bfe5968"
   },
   "outputs": [],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3F7GlsPlEaUT"
   },
   "outputs": [],
   "source": [
    "# manually define the metrics (if not pulled above) and the error percent\n",
    "metrics = [-12.173933555293633,\n",
    "           -15.870960965201313,\n",
    "           -19.916924903954175,\n",
    "           -28.505283826228215]\n",
    "\n",
    "error_percent = [24.16, 23.32, 23.52, 22.99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "tLGDKkb8EaUU",
    "outputId": "08cd3a2b-aa31-4ae2-ec1a-4ea4aec0d5df",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for idx, model_str in enumerate(cub_names):\n",
    "    ax.plot(error_percent[idx], metrics[idx], 'o', label=model_str)\n",
    "    \n",
    "ax.set_xlim(25, 22.5)  # decreasing time\n",
    "plt.xlabel(\"Test error (percent)\")\n",
    "plt.ylabel(r\"$\\widehat{\\alpha}$\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wVHNcriPEaUU"
   },
   "source": [
    "So, this plot supports that our metric also tracks test accuracy well for a variety of architectures on a completely different classification task than ImageNet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BCahb1YuEaUU"
   },
   "source": [
    "### References and implementation details\n",
    "The major improvement we make over the work mentioned above is our handling of convolutional layers: our approach at looking at the covariance of convolutional layers is both more principled and over an order of magnitude faster than [the code](https://github.com/CalculatedContent/WeightWatcher) released by the authors.\n",
    "\n",
    "\n",
    "Papers:\n",
    "\n",
    "[*Traditional and Heavy-Tailed Self Regularization in Neural Network Models*](https://arxiv.org/abs/1901.08276) by Martin and Mahoney \n",
    "\n",
    "[*Predicting trends in the quality of state-of-the-art neural networks without access to training or testing data*](https://arxiv.org/abs/2002.06716) by Martin, Peng, and Mahoney.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Copy of Tutorial 3 - SpectralAnalysis.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
